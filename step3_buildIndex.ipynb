{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c6ae1b-30d2-4b6a-a482-cb3b9cedb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import glob\n",
    "import collections\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,GroupKFold\n",
    "import torch\n",
    "# pip install prefetch_generator\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "from  transformers import AdamW, AutoTokenizer,AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Seeds basic parameters for reproductibility of results\n",
    "    Arguments:\n",
    "        seed {int} -- Number of the seed\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "SEED=2020\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7f6089-b309-4a04-ab86-c5cebedb983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT_PATH = \"/root/bert_path/sentence-transformers_all-MiniLM-L6-v2\"\n",
    "BERT_PATH = \"/root/bert_path/sentence-transformer-all-mpnet-base-v2\"\n",
    "# BERT_PATH = \"./pretrain_models/deberta-v3-xsmall\"\n",
    "MODEL_PATH = \"./save/recall_new/recall_resize.bin\"\n",
    "PROMPT_LEN = 512\n",
    "WIKI_LEN = 512\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 2048\n",
    "DEVICE = 'cuda'\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1,2,3'\n",
    "data = pd.read_parquet('./small_wiki_data/data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1072df4d-cbbd-414b-a060-68f82d145060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russell Epstein</td>\n",
       "      <td>Russell Epstein</td>\n",
       "      <td>Russell Epstein is a professor of psychology a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russell Epstein</td>\n",
       "      <td>Education</td>\n",
       "      <td>Epstein received an undergraduate degree in ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ambient device</td>\n",
       "      <td>Ambient device</td>\n",
       "      <td>Ambient devices are a type of consumer electro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ambient device</td>\n",
       "      <td>Purpose</td>\n",
       "      <td>The purpose of ambient devices is to enable im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ambient device</td>\n",
       "      <td>History</td>\n",
       "      <td>The concept of ambient devices can be traced b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title          section  \\\n",
       "0  Russell Epstein  Russell Epstein   \n",
       "1  Russell Epstein        Education   \n",
       "2   Ambient device   Ambient device   \n",
       "3   Ambient device          Purpose   \n",
       "4   Ambient device          History   \n",
       "\n",
       "                                                text  \n",
       "0  Russell Epstein is a professor of psychology a...  \n",
       "1  Epstein received an undergraduate degree in ph...  \n",
       "2  Ambient devices are a type of consumer electro...  \n",
       "3  The purpose of ambient devices is to enable im...  \n",
       "4  The concept of ambient devices can be traced b...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e1197e-bba3-4c57-aa8e-b39b3ad9d1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2101279, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff2c20a7-54b1-4466-b8c5-c5677e81ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['context'] = data.apply(lambda row : ' '.join(str(row[x]) for x in ['title', 'section','text']),axis=1)\n",
    "# data['context'] = data.apply(lambda row: row['title'] + ' '.join(list(row['categories'])) + row['text'],axis=1)\n",
    "# data = data[['id','file','context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "853685a9-2a86-44ec-97d4-1e53af693892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Russell Epstein Russell Epstein Russell Epstein is a professor of psychology at the University of Pennsylvania, who studies neural mechanisms underlying visual scene perception, event perception, object recognition, and spatial navigation in humans. His lab studies the role of the Parahippocampal and retrosplenial cortices in determining how people orient themselves relative to their surroundings.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0,'context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f9825d-c024-4e2b-bfb6-e802c99c6aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>text</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russell Epstein</td>\n",
       "      <td>Russell Epstein</td>\n",
       "      <td>Russell Epstein is a professor of psychology a...</td>\n",
       "      <td>Russell Epstein Russell Epstein Russell Epstei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russell Epstein</td>\n",
       "      <td>Education</td>\n",
       "      <td>Epstein received an undergraduate degree in ph...</td>\n",
       "      <td>Russell Epstein Education Epstein received an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ambient device</td>\n",
       "      <td>Ambient device</td>\n",
       "      <td>Ambient devices are a type of consumer electro...</td>\n",
       "      <td>Ambient device Ambient device Ambient devices ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ambient device</td>\n",
       "      <td>Purpose</td>\n",
       "      <td>The purpose of ambient devices is to enable im...</td>\n",
       "      <td>Ambient device Purpose The purpose of ambient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ambient device</td>\n",
       "      <td>History</td>\n",
       "      <td>The concept of ambient devices can be traced b...</td>\n",
       "      <td>Ambient device History The concept of ambient ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title          section  \\\n",
       "0  Russell Epstein  Russell Epstein   \n",
       "1  Russell Epstein        Education   \n",
       "2   Ambient device   Ambient device   \n",
       "3   Ambient device          Purpose   \n",
       "4   Ambient device          History   \n",
       "\n",
       "                                                text  \\\n",
       "0  Russell Epstein is a professor of psychology a...   \n",
       "1  Epstein received an undergraduate degree in ph...   \n",
       "2  Ambient devices are a type of consumer electro...   \n",
       "3  The purpose of ambient devices is to enable im...   \n",
       "4  The concept of ambient devices can be traced b...   \n",
       "\n",
       "                                             context  \n",
       "0  Russell Epstein Russell Epstein Russell Epstei...  \n",
       "1  Russell Epstein Education Epstein received an ...  \n",
       "2  Ambient device Ambient device Ambient devices ...  \n",
       "3  Ambient device Purpose The purpose of ambient ...  \n",
       "4  Ambient device History The concept of ambient ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5f0cd6-1fc4-4c11-a636-953f8e25341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class RecallModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RecallModel, self).__init__()\n",
    "        self.bert_model = AutoModel.from_pretrained(BERT_PATH)\n",
    "\n",
    "        self.mean_pooler = MeanPooling()\n",
    "\n",
    "    def mask_mean(self, x, mask=None):\n",
    "        if mask != None:\n",
    "            mask_x = x * (mask.unsqueeze(-1))\n",
    "            x_sum = torch.sum(mask_x, dim=1)\n",
    "            re_x = torch.div(x_sum, torch.sum(mask, dim=1).unsqueeze(-1))\n",
    "        else:\n",
    "            x_sum = torch.sum(x, dim=1)\n",
    "            re_x = torch.div(x_sum, x.size()[1])\n",
    "        return re_x\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        attention_mask = input_ids > 0\n",
    "        out = self.bert_model(input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        x = self.mean_pooler(out, attention_mask)\n",
    "\n",
    "        # x = out[:, 0, :]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d595f850-fd24-427a-b34e-2b45be3fed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader_class = partial(DataLoader, pin_memory=True, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fd923a8-58b5-4c67-87a7-226af0f3ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= RecallModel()\n",
    "from collections import OrderedDict\n",
    "def load_param(model_path):\n",
    "    state_dict = torch.load(model_path, map_location='cpu')\n",
    "    params = OrderedDict()\n",
    "    for name, param in state_dict.items():\n",
    "        name = '.'.join(name.split('.')[1:])\n",
    "        params[name] = param\n",
    "    return params\n",
    "model.load_state_dict(load_param('./save/recall_base/recall_pagrah_best.bin'))\n",
    "model.to(DEVICE)\n",
    "model = torch.nn.parallel.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0490c3bc-2f97-4f66-a16a-727c4131a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "class LLMRecallDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(BERT_PATH, use_fast=True)\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        ids = self.data.loc[index, 'context']\n",
    "        ids = self.tokenizer.encode(ids, add_special_tokens=False)\n",
    "        if len(ids) > 510:\n",
    "            ids = [101] + ids[:510] + [102]\n",
    "        else:\n",
    "            ids = [101] + ids + [102]\n",
    "        return ids\n",
    "    def collate_fn(self, batch):\n",
    "        def sequence_padding(inputs, length=None, padding=0):\n",
    "            \"\"\"\n",
    "            Numpy函数，将序列padding到同一长度\n",
    "            \"\"\"\n",
    "            if length is None:\n",
    "                length = max([len(x) for x in inputs])\n",
    "\n",
    "            pad_width = [(0, 0) for _ in np.shape(inputs[0])]\n",
    "            outputs = []\n",
    "            for x in inputs:\n",
    "                x = x[:length]\n",
    "                pad_width[0] = (0, length - len(x))\n",
    "                x = np.pad(x, pad_width, 'constant', constant_values=padding)\n",
    "                outputs.append(x)\n",
    "\n",
    "            return np.array(outputs, dtype='int64')\n",
    "\n",
    "        batch_ids = torch.tensor(sequence_padding(batch), dtype=torch.long)\n",
    "        \n",
    "        return batch_ids\n",
    "\n",
    "        \n",
    "class DataLoaderX(torch.utils.data.DataLoader):\n",
    "    '''\n",
    "        replace DataLoader with PrefetchDataLoader\n",
    "    '''\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())  \n",
    "\n",
    "    \n",
    "def get_loader(prompt,batch_size,train_mode=True,num_workers=4):\n",
    "    ds_df = LLMRecallDataSet(prompt)\n",
    "    # loader = DataLoaderX(ds_df, batch_size=batch_size if train_mode else batch_size//2, shuffle=train_mode, num_workers=num_workers,pin_memory=True,\n",
    "    #                                      collate_fn=ds_df.collate_fn, drop_last=train_mode)\n",
    "    loader = dataloader_class(ds_df, batch_size=batch_size, shuffle=False,collate_fn=ds_df.collate_fn,num_workers=num_workers)\n",
    "    loader.num = len(ds_df)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa0b2a55-2483-4606-a529-04364a11526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_label():\n",
    "    loader=get_loader(data.loc[:100].reset_index(drop=True),batch_size=2,train_mode=True,num_workers=0)\n",
    "    model= RecallModel()\n",
    "    print('models paramters:', sum(p.numel() for p in model.parameters()))\n",
    "    for token_ids in loader:\n",
    "        # print(token_ids)\n",
    "        # print(labels)\n",
    "        prob=model(token_ids)\n",
    "        print(prob.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ba873-a6ac-43bb-86e3-a14c1104cf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05ca44a8d434611abf54203b2d440a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/514 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "loader = get_loader(data, 4096, False, num_workers=32)\n",
    "from torch.cuda.amp import autocast\n",
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatIP(768)\n",
    "model.eval()\n",
    "idx = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(loader):\n",
    "        ids = batch\n",
    "        ids = ids.to(DEVICE)\n",
    "        with autocast():\n",
    "            output = model(ids).cpu().detach().numpy()\n",
    "        faiss.normalize_L2(output)\n",
    "        index.add(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf0566-3267-497b-8ccf-0ac737988aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, './wiki_index/small_paragh_wiki_data.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae66ca9-8808-4b79-a2a1-999f4fd2dd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chr_env",
   "language": "python",
   "name": "chr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
